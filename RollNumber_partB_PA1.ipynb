{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RollNumber_partB_PA1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamdjalil/ChordDiagram/blob/master/RollNumber_partB_PA1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vvRXrJXFIbc"
      },
      "source": [
        "## CS436/5310/EE513 - Fall 2021 - Part B\n",
        "\n",
        "#### Important Instructions and Submission Guidelines:\n",
        "- Naming convention for submission of this notebook is `RollNumber_partB_PA1.ipynb` where. For example: `22100075_partB_PA1.ipynb`\n",
        "- All the cells <b>must</b> be run once before submission. If your submission's cells are not showing the results (plots etc.), marks wil be deducted\n",
        "- Only the code written within this notebook's marked areas will be considered while grading. No other files will be entertained\n",
        "- You are advised to follow good programming practies including approriate variable naming and making use of logical comments \n",
        "\n",
        "\n",
        "The university honor code should be maintained. Any violation, if found, will result in disciplinary action. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBpsb1rIbri"
      },
      "source": [
        "<b>Double click here to enter your name and roll number:  \n",
        "Name: \n",
        "\n",
        "Roll Number: \n",
        "</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MLfF-HJIQRA"
      },
      "source": [
        "#### Retireving The Dataset\n",
        "\n",
        "Link to the required dataset for this part: https://drive.google.com/file/d/1p_8_aR-xpiMQuaISrvG7TYyzB0rmsKA1/view?usp=sharing\n",
        "\n",
        "You have to add this .zip dataset to your drive which you will mount in the next cell\n",
        "\n",
        "The dataset includes three sub-folders:\n",
        "- deer\n",
        "- cow\n",
        "- coyote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcx9U7FWI_96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4718df-27d6-4314-8e2d-c3aca7864a29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Edit this address so that it points to the dataset's zipped file on your Google Drive\n",
        "!unzip -o -q \"/content/drive/MyDrive/CompVision/PA1_PartB_datasets.zip\" -d \"/content/data/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghNRcK1cEZaF"
      },
      "source": [
        "!unzip -o -q \"/content/drive/MyDrive/CompVision/PA1_PartB_datasets.zip\" -d \"/content/data/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_9vueR2oicE"
      },
      "source": [
        "# making all the necessary imports here\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.layers import Input,Activation,Dense,Flatten,Conv2D,MaxPooling2D,Dropout,AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "# you may include more libraries here if needed"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgGO7xYdomZl"
      },
      "source": [
        "#### Binary Classification Task\n",
        "\n",
        "In this task you will have to make a binary classifier using Keras which can distinguish between the following classes:\n",
        "- cow\n",
        "- deer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp9Pn6dJpQvt"
      },
      "source": [
        "### Edit Here ###\n",
        "BATCH_SIZE = 32 # Initliaze this with an appropriate int value\n",
        "#################\n",
        "\n",
        "SHAPE = (150,150,3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTFUQgrWqFHC"
      },
      "source": [
        "# defining and initializing batch generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        brightness_range=(1,0.8),\n",
        "        vertical_flip=True,\n",
        "        rotation_range=10,\n",
        "        horizontal_flip=True,validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2KCum3iqIkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473d1806-faa7-47c1-8aed-f1db40d99b13"
      },
      "source": [
        "# defining and initilazing train set and validation set generators. You 'may' have to edit these paths in case of directory errors\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/PA1_PartB_dataset/Binary_dataset',\n",
        "        target_size=SHAPE[:-1],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary', subset=\"training\")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/PA1_PartB_dataset/Binary_dataset',\n",
        "        target_size=SHAPE[:-1],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary', subset=\"validation\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 320 images belonging to 2 classes.\n",
            "Found 80 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZdmzp4aqLqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b39c822-c929-4c70-937f-7145d3f26cde"
      },
      "source": [
        "# declare and initilalize your model here\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = SHAPE, activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a third convolutional layer\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a fourth convolutional layer\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 64, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "### Code Here ###\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                401472    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 642,369\n",
            "Trainable params: 642,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El1WS4sHq6XJ"
      },
      "source": [
        "# compiling your model with an optimizer and loss metric. You can change these parameters to tweak with your model's performance\n",
        "adam = Adam(learning_rate = 1e-3)\n",
        "classifier.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xDavew3fWki"
      },
      "source": [
        "filepath=\"weights2.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCPQ6Qrrnli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf460c9-7b34-4a3d-8ba7-01063de677f5"
      },
      "source": [
        "# required baseline accuracy is 80%. Above that, the better the accuracy, the higher you will score\n",
        "\n",
        "### Edit Here ###\n",
        "EPOCH = 50 # Initliaze this with an appropriate int value\n",
        "#################\n",
        "\n",
        "hist = classifier.fit_generator(train_generator, epochs = EPOCH, validation_data = validation_generator, callbacks = callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6906 - val_accuracy: 0.7250\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72500, saving model to weights2.best.hdf5\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6937 - accuracy: 0.5031 - val_loss: 0.6886 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.72500\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6891 - accuracy: 0.5625 - val_loss: 0.6884 - val_accuracy: 0.5125\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.72500\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6842 - accuracy: 0.5031 - val_loss: 0.6736 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72500\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6667 - accuracy: 0.5813 - val_loss: 0.6166 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72500\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6606 - accuracy: 0.6219 - val_loss: 0.6093 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.72500 to 0.73750, saving model to weights2.best.hdf5\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6497 - accuracy: 0.6094 - val_loss: 0.6143 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73750\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6487 - accuracy: 0.6000 - val_loss: 0.5994 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.73750\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6082 - accuracy: 0.6562 - val_loss: 0.5951 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.73750\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.5974 - accuracy: 0.6875 - val_loss: 0.6022 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.73750\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5911 - accuracy: 0.6969 - val_loss: 0.6176 - val_accuracy: 0.6375\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.73750\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5953 - accuracy: 0.6844 - val_loss: 0.6045 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.73750\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6512 - accuracy: 0.5969 - val_loss: 0.6309 - val_accuracy: 0.6625\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.73750\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6012 - accuracy: 0.6438 - val_loss: 0.5860 - val_accuracy: 0.7125\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.73750\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5537 - accuracy: 0.6719 - val_loss: 0.5580 - val_accuracy: 0.7250\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.73750\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5290 - accuracy: 0.7531 - val_loss: 0.5313 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.73750 to 0.77500, saving model to weights2.best.hdf5\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.4941 - accuracy: 0.7688 - val_loss: 0.5972 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.77500\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4984 - accuracy: 0.7531 - val_loss: 0.5734 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.77500\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.4767 - accuracy: 0.7719 - val_loss: 0.5940 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77500\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4438 - accuracy: 0.8156 - val_loss: 0.6129 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77500\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4563 - accuracy: 0.7844 - val_loss: 0.6551 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.77500\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4593 - accuracy: 0.8031 - val_loss: 0.6305 - val_accuracy: 0.7125\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.77500\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4348 - accuracy: 0.8250 - val_loss: 0.5199 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.77500 to 0.80000, saving model to weights2.best.hdf5\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4236 - accuracy: 0.8094 - val_loss: 0.5540 - val_accuracy: 0.7250\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.80000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4065 - accuracy: 0.8250 - val_loss: 0.5482 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.80000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3485 - accuracy: 0.8656 - val_loss: 0.6376 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.80000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3682 - accuracy: 0.8438 - val_loss: 0.6528 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.80000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3293 - accuracy: 0.8594 - val_loss: 0.5355 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.80000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4035 - accuracy: 0.8219 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.80000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3076 - accuracy: 0.8687 - val_loss: 0.5483 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.80000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3068 - accuracy: 0.8594 - val_loss: 0.6059 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.80000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2697 - accuracy: 0.8813 - val_loss: 0.7343 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.80000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2996 - accuracy: 0.8687 - val_loss: 0.7815 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.80000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3324 - accuracy: 0.8687 - val_loss: 0.5541 - val_accuracy: 0.7625\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.80000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2971 - accuracy: 0.8906 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.80000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.3076 - accuracy: 0.8656 - val_loss: 0.6307 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.80000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2357 - accuracy: 0.9062 - val_loss: 0.6144 - val_accuracy: 0.7625\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.80000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1787 - accuracy: 0.9187 - val_loss: 0.6315 - val_accuracy: 0.7875\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.80000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2201 - accuracy: 0.9094 - val_loss: 0.8111 - val_accuracy: 0.7625\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.80000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1973 - accuracy: 0.9344 - val_loss: 0.7399 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.80000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1738 - accuracy: 0.9312 - val_loss: 0.7409 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.80000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2015 - accuracy: 0.9187 - val_loss: 0.6090 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.80000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1856 - accuracy: 0.9219 - val_loss: 0.6767 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.80000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2273 - accuracy: 0.9062 - val_loss: 0.6144 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.80000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1639 - accuracy: 0.9281 - val_loss: 0.7774 - val_accuracy: 0.7625\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.80000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.2513 - accuracy: 0.9031 - val_loss: 0.7561 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.80000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1581 - accuracy: 0.9312 - val_loss: 0.7043 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.80000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1383 - accuracy: 0.9500 - val_loss: 0.7159 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.80000 to 0.81250, saving model to weights2.best.hdf5\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1357 - accuracy: 0.9438 - val_loss: 0.8105 - val_accuracy: 0.8250\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.81250 to 0.82500, saving model to weights2.best.hdf5\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.1484 - accuracy: 0.9344 - val_loss: 0.9003 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.82500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWP-RBqtm8Eo"
      },
      "source": [
        "# save the model into and hdf5 file format\n",
        "classifier.save(filepath)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3yPHPfUmOun"
      },
      "source": [
        "# testing the model using model.predict\n",
        "predictions = classifier.predict(validation_generator, batch_size = 32)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8d9t69rO1dI"
      },
      "source": [
        "print(predictions\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDidCgYIinos"
      },
      "source": [
        "# using the threshold, make your predictions binary\n",
        "\n",
        "THRESHOLD = 0.7\n",
        "\n",
        "### Code here ###\n",
        "t_preds = []\n",
        "for pred in predictions:\n",
        "  if pred[0] < 0.7:\n",
        "    t_preds.append([0])\n",
        "  else:\n",
        "    t_preds.append([1])\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvLvejBt1-Eb"
      },
      "source": [
        "# print a few images (at least 10) with their labels as given by your model to visulaize your model's performance\n",
        "from keras.preprocessing import image\n",
        "\n",
        "### Code here ###\n",
        "# test_image = image.load_img('/content/data/PA1_PartB_dataset/Binary_dataset/cow/6688.JPG')\n",
        "# test_image = image.img_to_array(test_image)\n",
        "# test_image = np.expand_dims(test_image, axis = 0)\n",
        "image = image.load_img(\n",
        "    '/content/data/PA1_PartB_dataset/Binary_dataset/deer/9438.JPG', grayscale=False, color_mode=\"rgb\", target_size=SHAPE, interpolation=\"nearest\"\n",
        ")\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "predictions = classifier.predict(input_arr)\n",
        "\n",
        "# print(train_datagen.next())\n",
        "# print(training_set.class_indices)\n",
        "# if result[0][0] == 1:\n",
        "#     prediction = 'dog'\n",
        "# else:\n",
        "#     prediction = 'cat'\n",
        "# print(prediction)\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwBB-kX2dR-o",
        "outputId": "da7e17ba-fab4-48be-c24d-cfb4c55895ef"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INSkrrU-k-8l"
      },
      "source": [
        "#### Fining Tuning Your Model\n",
        "Now you have to edit your model to learn three-class classification for the following classes:\n",
        "- deer\n",
        "- cow\n",
        "- coyote\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1cfyWYEpcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8083c023-3b00-4a50-f969-247a2dedb7fd"
      },
      "source": [
        "# defining and initilazing train set and validation set generators. You 'may' have to edit these paths in case of directory errors\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/PA1_PartB_dataset/Three_class_dataset',\n",
        "        target_size=SHAPE[:-1],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', subset=\"training\")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/PA1_PartB_dataset/Three_class_dataset',\n",
        "        target_size=SHAPE[:-1],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', subset=\"validation\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 480 images belonging to 3 classes.\n",
            "Found 120 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1unoKGVzouzd"
      },
      "source": [
        "# Freeze all the layers of the model except the dense layers in the end of model\n",
        "\n",
        "### Code Here ###\n",
        "\n",
        "classifier.layers[0].traianble = False\n",
        "classifier.layers[1].traianble = False\n",
        "classifier.layers[2].traianble = False\n",
        "classifier.layers[3].traianble = False\n",
        "classifier.layers[4].traianble = False\n",
        "classifier.layers[5].traianble = False\n",
        "classifier.layers[6].traianble = False\n",
        "classifier.layers[7].traianble = False\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ZyETbcs_J0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f2a7ad-19e7-405a-ff8d-29d32706cd86"
      },
      "source": [
        "# Make a new Dense Layer (it should predict 3 classes now) and connect it to the second-last layer of network \n",
        "\n",
        "### Code Here ###\n",
        "from keras.models import Model\n",
        "\n",
        "model2 = Model(classifier.input, classifier.layers[-3].output)\n",
        "# model2.add(Dense(units = 64, activation = 'relu'))\n",
        "# model2.add(Dense(units = 3, activation = 'softmax'))\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_input (InputLayer)    [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "=================================================================\n",
            "Total params: 240,832\n",
            "Trainable params: 240,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auwA7WVWzO6a"
      },
      "source": [
        "# Make a new model with the input of previous model as input and the new dense layer as output\n",
        "new_model = None\n",
        "\n",
        "### Code Here ###\n",
        "\n",
        "\n",
        "\n",
        "#################\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAr6bhXpAyYu"
      },
      "source": [
        "# compiling your model with an optimizer and loss metric. You can change these parameters to tweak with your model's performance\n",
        "adam = Adam(lr=1e-3)\n",
        "new_model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlyhTqCPAW6t"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJBcQWgezO6c"
      },
      "source": [
        "# required baseline accuracy is 80%. Above that, the better the accuracy, the higher you will score\n",
        "\n",
        "### Edit Here ###\n",
        "EPOCH2 = None  # Initliaze this with an appropriate int value\n",
        "#################\n",
        "\n",
        "hist2 = hist2 = new_model.fit_generator(train_generator, epochs = EPOCH2, validation_data = validation_generator, callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUF25nqg5Ckd"
      },
      "source": [
        "# save the model into and hdf5 file format\n",
        "new_model.save(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbPND9LkzO6m"
      },
      "source": [
        "# testing the model using model.predict\n",
        "new_predictions = model2.predict(validation_generator, batch_size = BATCH_SIZE)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8_kzMLnnNbk"
      },
      "source": [
        "# for each image, find the index of the highest prediction and use it to determine their label\n",
        "\n",
        "### Code here ###\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUYf_Q8t2CUW"
      },
      "source": [
        "# print a few images (at least 10) with their labels as given by your model to visulaize your model's performance\n",
        "\n",
        "### Code here ###\n",
        "\n",
        "\n",
        "\n",
        "#################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}